{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp_-4ggtiY1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNlhpwHhAOZB",
        "colab_type": "code",
        "outputId": "a5e8286a-e9df-4526-c3fb-c804b4705bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK00cusFCEIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import random\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split # Helps with organizing data for training\n",
        "from sklearn.metrics import confusion_matrix # Helps present results as a confusion-matri"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQFVjyb--m8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/data/leapGestRecog.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUjWWbgpUuf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip your data set here \n",
        "!rm -R data/\n",
        "!unzip data-4.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRsQI7hIYz4k",
        "colab_type": "code",
        "outputId": "6be222c6-6f7a-4023-b4ad-3d6c798a3e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "imagepaths = []\n",
        "\n",
        "# Go through all the files and subdirectories inside a folder and save path to images inside list\n",
        "for root, dirs, files in os.walk(\"./data\", topdown=False): \n",
        "  for name in files:\n",
        "    path = os.path.join(root, name)\n",
        "    if path.endswith(\"png\"): # We want only the images\n",
        "      imagepaths.append(path)\n",
        "\n",
        "print(len(imagepaths)) # If > 0, then a PNG image was loaded\n",
        "random.shuffle(imagepaths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkoBxe__jGRz",
        "colab_type": "text"
      },
      "source": [
        "We first extract all the paths of the .png files and then shuffle it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJVPyWspZXeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function is used more for debugging and showing results later. It plots the image into the notebook\n",
        "\n",
        "def plot_image(path):\n",
        "  img = cv2.imread(path) # Reads the image into a numpy.array\n",
        "  img_cvt = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (RGB)\n",
        "  img_cvt = cv2.resize(img_cvt , (300,300))\n",
        "  print(img_cvt.shape) # Prints the shape of the image just to check\n",
        "  plt.grid(False) # Without grid so we can see better\n",
        "  plt.imshow(img_cvt) # Shows the image\n",
        "  plt.xlabel(\"Width\")\n",
        "  plt.ylabel(\"Height\")\n",
        "  plt.title(\"Image \" + path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGl0SqSjUys",
        "colab_type": "text"
      },
      "source": [
        "This function is for debuging and checking how the image looks before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubDnQPvZaSV1",
        "colab_type": "code",
        "outputId": "d20da0e6-a84f-43c1-c71a-c5ba151a8bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X = [] # Image data\n",
        "y = [] # Labels\n",
        "\n",
        "# Loops through imagepaths to load images and labels into arrays\n",
        "for path in imagepaths:\n",
        "  img = cv2.imread(path) # Reads image and returns np.array\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (GRAY)\n",
        "  img = cv2.resize(img, (300, 300)) # Reduce image size so training can be faster\n",
        "  X.append(img)\n",
        "\n",
        "  # Processing label in image path\n",
        "  category = path.split(\"/\")[3]\n",
        "  label = int(category.split(\"_\")[1]) # We need to convert 10_down to 00_down, or else it crashes\n",
        "  y.append(label)\n",
        "\n",
        "# Turn X and y into np.array to speed up train_test_split\n",
        "X = np.array(X, dtype=\"float16\")\n",
        "print(X.shape)\n",
        "X = X.reshape(len(imagepaths), 300, 300, 1) # Needed to reshape so CNN knows it's different images\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Images loaded: \", len(X))\n",
        "print(\"Labels loaded: \", len(y))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 300, 300)\n",
            "Images loaded:  7000\n",
            "Labels loaded:  7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycx7zrfCjdP6",
        "colab_type": "text"
      },
      "source": [
        "We preprocess the image and then create two arrays X and Y with the image and labels respectively "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbo-IKrz5Nag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts = 0.3 # Percentage of images that we want to use for testing. The rest is used for training.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt6zfFzZjnZG",
        "colab_type": "text"
      },
      "source": [
        "We then split the dataSet intpo Training and Testing sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lEYEp8K85GO",
        "colab_type": "code",
        "outputId": "faeded92-a179-4929-87f8-af7323713a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# Construction of model\n",
        "\n",
        "layers =[\n",
        "         tf.keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(300, 300, 1)),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2)),\n",
        "         tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2)),\n",
        "         tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "         tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2)),\n",
        "         tf.keras.layers.Flatten(),\n",
        "         tf.keras.layers.Dense(128, activation='relu'),\n",
        "         tf.keras.layers.Dense(7, activation='softmax')\n",
        "]\n",
        "\n",
        "model = tf.keras.Sequential(layers)\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss = tf.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "# Trains the model for a given number of epochs (iterations on a dataset) and validates it.\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=2, validation_data=(X_test, y_test))\n",
        "model.save('custModelOrgRes-9.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4900 samples, validate on 2100 samples\n",
            "Epoch 1/5\n",
            "4900/4900 - 897s - loss: 10.1494 - sparse_categorical_accuracy: 0.8749 - val_loss: 0.0531 - val_sparse_categorical_accuracy: 0.9862\n",
            "Epoch 2/5\n",
            "4900/4900 - 905s - loss: 0.0149 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0411 - val_sparse_categorical_accuracy: 0.9890\n",
            "Epoch 3/5\n",
            "4900/4900 - 899s - loss: 0.0112 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0303 - val_sparse_categorical_accuracy: 0.9943\n",
            "Epoch 4/5\n",
            "4900/4900 - 909s - loss: 0.0092 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0281 - val_sparse_categorical_accuracy: 0.9943\n",
            "Epoch 5/5\n",
            "4900/4900 - 907s - loss: 0.0094 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FgLZnjxkgzo",
        "colab_type": "text"
      },
      "source": [
        "The ML model which currently takes the images with a res of 300 x 300.\n",
        "\n",
        "On training for 5 epochs and adam optimizer we get an accuracy of 99.48% "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMWOngCnnanu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test accuracy: {:2.2f}%'.format(test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}